#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¦äº•ç¥ç¤¾è³‡æ–™å¢å¼·å·¥å…· - ChromaDB å‘é‡è³‡æ–™åº«å¯¦ä½œ
è² è²¬å°‡ markdown æª”æ¡ˆæ˜ å°„åˆ° ChromaDB ä¸¦æä¾› GPT-4o-mini å•ç­”åŠŸèƒ½
"""

import os
import re
import json
import logging
from typing import List, Dict, Any, Tuple, Optional
from pathlib import Path
import chromadb
from chromadb.utils import embedding_functions
import openai
from openai import OpenAI
from dotenv import load_dotenv
import hashlib

class ChromaDBManager:
    """ChromaDB å‘é‡è³‡æ–™åº«ç®¡ç†å™¨"""
    
    def __init__(self, db_path: str = "./chroma_db", collection_name: str = "fukui_tourism"):
        """åˆå§‹åŒ– ChromaDB ç®¡ç†å™¨
        
        Args:
            db_path: è³‡æ–™åº«å„²å­˜è·¯å¾‘
            collection_name: é›†åˆåç¨±
        """
        self.db_path = Path(db_path)
        self.collection_name = collection_name
        self.setup_logging()
        self.setup_environment()
        self.setup_chromadb()
        self.setup_openai()
        
    def setup_logging(self):
        """è¨­å®šæ—¥èªŒ"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('chromadb.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def setup_environment(self):
        """è¼‰å…¥ç’°å¢ƒè®Šæ•¸"""
        load_dotenv()
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        if not self.openai_api_key:
            raise ValueError("æœªæ‰¾åˆ° OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸")
        self.logger.info("ç’°å¢ƒè®Šæ•¸è¼‰å…¥æˆåŠŸ")
        
    def setup_chromadb(self):
        """è¨­å®š ChromaDB"""
        try:
            # å»ºç«‹è³‡æ–™åº«ç›®éŒ„
            self.db_path.mkdir(parents=True, exist_ok=True)
            
            # ä½¿ç”¨æ–°çš„ ChromaDB å®¢æˆ¶ç«¯åˆå§‹åŒ–æ–¹å¼
            self.client = chromadb.PersistentClient(path=str(self.db_path))
            
            # æš«æ™‚ä½¿ç”¨é è¨­çš„ embedding å‡½å¼ï¼Œé¿å…ç‰ˆæœ¬ç›¸å®¹æ€§å•é¡Œ
            self.collection = self.client.get_or_create_collection(
                name=self.collection_name,
                metadata={"description": "ç¦äº•ç¸£è§€å…‰æ™¯é»å’Œç¥ç¤¾è³‡è¨Š"}
            )
            
            self.logger.info(f"ChromaDB åˆå§‹åŒ–æˆåŠŸï¼Œé›†åˆåç¨±ï¼š{self.collection_name}")
            
        except Exception as e:
            self.logger.error(f"ChromaDB åˆå§‹åŒ–å¤±æ•—ï¼š{e}")
            raise
            
    def setup_openai(self):
        """è¨­å®š OpenAI å®¢æˆ¶ç«¯"""
        try:
            self.openai_client = OpenAI(api_key=self.openai_api_key)
            self.logger.info("OpenAI å®¢æˆ¶ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"OpenAI å®¢æˆ¶ç«¯åˆå§‹åŒ–å¤±æ•—ï¼š{e}")
            raise
    
    def parse_markdown_sections(self, content: str, source_type: str) -> List[Dict[str, Any]]:
        """è§£æ Markdown å…§å®¹ç‚ºçµæ§‹åŒ–è³‡æ–™
        
        Args:
            content: Markdown å…§å®¹
            source_type: ä¾†æºé¡å‹ ('locations' æˆ– 'shrines')
            
        Returns:
            è§£æå¾Œçš„çµæ§‹åŒ–è³‡æ–™æ¸…å–®
        """
        sections = []
        
        # åˆ†å‰²å„å€‹æ™¯é»/ç¥ç¤¾å€å¡Š
        if source_type == "locations":
            pattern = r'## (\d+)\. (.+?)\n'
        else:  # shrines
            pattern = r'## (\d+)\. (.+?)\n'
            
        matches = list(re.finditer(pattern, content))
        
        for i, match in enumerate(matches):
            start_pos = match.start()
            end_pos = matches[i + 1].start() if i + 1 < len(matches) else len(content)
            
            section_content = content[start_pos:end_pos].strip()
            section_data = self.extract_section_data(section_content, source_type)
            
            if section_data:
                sections.append(section_data)
                
        return sections
    
    def extract_section_data(self, section_content: str, source_type: str) -> Optional[Dict[str, Any]]:
        """å¾å€å¡Šå…§å®¹æå–çµæ§‹åŒ–è³‡æ–™
        
        Args:
            section_content: å€å¡Šå…§å®¹
            source_type: ä¾†æºé¡å‹
            
        Returns:
            çµæ§‹åŒ–è³‡æ–™å­—å…¸
        """
        try:
            data = {"source_type": source_type}
            
            # æå–æ¨™é¡Œ
            title_match = re.search(r'## \d+\. (.+)', section_content)
            if title_match:
                data["title"] = title_match.group(1).strip()
                self.logger.debug(f"æå–æ¨™é¡ŒæˆåŠŸ: {data['title']}")
            else:
                self.logger.warning(f"ç„¡æ³•æå–æ¨™é¡Œï¼Œå…§å®¹é–‹é ­: {section_content[:100]}...")
            
            # æå–åŸºæœ¬è³‡è¨Šè¡¨æ ¼
            basic_info_pattern = r'\| é …ç›® \| å…§å®¹ \|\n\|------|------\|(.*?)\n\n'
            basic_info_match = re.search(basic_info_pattern, section_content, re.DOTALL)
            
            if basic_info_match:
                table_content = basic_info_match.group(1)
                if table_content:  # ç¢ºä¿ table_content ä¸æ˜¯ None
                    for row in table_content.split('\n'):
                        if '|' in row:
                            parts = [part.strip() for part in row.split('|') if part.strip()]
                            if len(parts) >= 2:
                                key = parts[0].strip()
                                value = parts[1].strip()
                                if key and value:  # ç¢ºä¿ key å’Œ value éƒ½ä¸æ˜¯ç©ºå­—ä¸²
                                    data[key] = value
                else:
                    self.logger.warning(f"åŸºæœ¬è³‡è¨Šè¡¨æ ¼å…§å®¹ç‚ºç©º")
            else:
                self.logger.warning(f"ç„¡æ³•æ‰¾åˆ°åŸºæœ¬è³‡è¨Šè¡¨æ ¼")
            
            # æå–è©³ç´°æè¿°
            desc_match = re.search(r'### è©³ç´°æè¿°\n\n(.*?)(?=\n### |$)', section_content, re.DOTALL)
            if desc_match:
                data["detailed_description"] = desc_match.group(1).strip()
            
            # æå–ç‡Ÿæ¥­æ™‚é–“ï¼ˆåƒ…é™æ™¯é»ï¼‰
            if source_type == "locations":
                hours_match = re.search(r'### ç‡Ÿæ¥­æ™‚é–“\n\n(.*?)(?=\n### |$)', section_content, re.DOTALL)
                if hours_match:
                    data["operating_hours"] = hours_match.group(1).strip()
            
            # æå–è©•è«–
            reviews_match = re.search(r'### éŠå®¢è©•è«–ç²¾é¸\n\n(.*?)(?=\n\*\*é—œéµæ¨™ç±¤|$)', section_content, re.DOTALL)
            if reviews_match:
                data["reviews"] = reviews_match.group(1).strip()
            
            # æå–é—œéµæ¨™ç±¤ - æ”¹é€²æ­£å‰‡è¡¨é”å¼ä»¥é©æ‡‰ä¸åŒæ ¼å¼
            tags_match = re.search(r'\*\*é—œéµæ¨™ç±¤ï¼š\*\* (.+?)(?:\n|$)', section_content, re.DOTALL)
            if tags_match:
                tags_text = tags_match.group(1).strip()
                if tags_text:  # ç¢ºä¿ tags_text ä¸æ˜¯ None æˆ–ç©ºå­—ä¸²
                    # ç§»é™¤å¯èƒ½çš„çµå°¾ç¬¦è™Ÿå’Œå¤šé¤˜ç©ºæ ¼
                    tags_text = tags_text.replace('\n', ' ').strip()
                    data["tags"] = [tag.strip() for tag in tags_text.split('|') if tag.strip()]
                    self.logger.debug(f"æå–æ¨™ç±¤æˆåŠŸ: {data['tags']}")
                else:
                    data["tags"] = []
            else:
                data["tags"] = []
                self.logger.warning(f"ç„¡æ³•æ‰¾åˆ°é—œéµæ¨™ç±¤")
            
            # å»ºç«‹å®Œæ•´æ–‡æœ¬ç”¨æ–¼åµŒå…¥
            data["full_text"] = section_content
            
            return data
            
        except Exception as e:
            self.logger.error(f"è§£æå€å¡Šè³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            self.logger.error(f"å•é¡Œå…§å®¹å‰100å­—ç¬¦: {section_content[:100] if section_content else 'None'}")
            return None
    
    def load_and_process_files(self, locations_file: str, shrines_file: str) -> Tuple[List[Dict], List[Dict]]:
        """è¼‰å…¥ä¸¦è™•ç† markdown æª”æ¡ˆ
        
        Args:
            locations_file: æ™¯é»æª”æ¡ˆè·¯å¾‘
            shrines_file: ç¥ç¤¾æª”æ¡ˆè·¯å¾‘
            
        Returns:
            è™•ç†å¾Œçš„æ™¯é»å’Œç¥ç¤¾è³‡æ–™
        """
        locations_data = []
        shrines_data = []
        
        # è™•ç†æ™¯é»æª”æ¡ˆ
        try:
            with open(locations_file, 'r', encoding='utf-8') as f:
                locations_content = f.read()
            locations_data = self.parse_markdown_sections(locations_content, "locations")
            self.logger.info(f"æˆåŠŸè§£æ {len(locations_data)} å€‹æ™¯é»")
        except Exception as e:
            self.logger.error(f"è¼‰å…¥æ™¯é»æª”æ¡ˆå¤±æ•—ï¼š{e}")
        
        # è™•ç†ç¥ç¤¾æª”æ¡ˆ
        try:
            with open(shrines_file, 'r', encoding='utf-8') as f:
                shrines_content = f.read()
            shrines_data = self.parse_markdown_sections(shrines_content, "shrines")
            self.logger.info(f"æˆåŠŸè§£æ {len(shrines_data)} å€‹ç¥ç¤¾")
        except Exception as e:
            self.logger.error(f"è¼‰å…¥ç¥ç¤¾æª”æ¡ˆå¤±æ•—ï¼š{e}")
        
        return locations_data, shrines_data
    
    def generate_document_id(self, data: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ–‡ä»¶å”¯ä¸€ ID
        
        Args:
            data: æ–‡ä»¶è³‡æ–™
            
        Returns:
            å”¯ä¸€ ID
        """
        # ä½¿ç”¨æ›´å¤šæ¬„ä½ä¾†ç¢ºä¿ ID çš„å”¯ä¸€æ€§
        source_type = data.get('source_type', '')
        title = data.get('title', '')
        address = data.get('åœ°å€', data.get('æ‰€åœ¨åœ°', ''))
        full_text_hash = hashlib.md5(data.get('full_text', '').encode('utf-8')).hexdigest()[:8]
        
        content = f"{source_type}-{title}-{address}-{full_text_hash}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def insert_documents(self, documents: List[Dict[str, Any]]) -> bool:
        """å°‡æ–‡ä»¶æ’å…¥ ChromaDB
        
        Args:
            documents: æ–‡ä»¶æ¸…å–®
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            if not documents:
                self.logger.warning("æ²’æœ‰æ–‡ä»¶éœ€è¦æ’å…¥")
                return True
                
            ids = []
            texts = []
            metadatas = []
            
            for doc in documents:
                doc_id = self.generate_document_id(doc)
                ids.append(doc_id)
                texts.append(doc.get("full_text", ""))
                
                # å»ºç«‹ metadataï¼ˆç§»é™¤ full_text é¿å…é‡è¤‡ï¼‰
                metadata = {k: v for k, v in doc.items() if k != "full_text"}
                # ç¢ºä¿æ‰€æœ‰å€¼éƒ½æ˜¯å­—ç¬¦ä¸²é¡å‹
                for key, value in metadata.items():
                    if isinstance(value, list):
                        metadata[key] = " | ".join(str(v) for v in value)
                    else:
                        metadata[key] = str(value)
                metadatas.append(metadata)
            
            # æ‰¹æ¬¡æ’å…¥
            self.collection.add(
                documents=texts,
                metadatas=metadatas,
                ids=ids
            )
            
            self.logger.info(f"æˆåŠŸæ’å…¥ {len(documents)} å€‹æ–‡ä»¶")
            return True
            
        except Exception as e:
            self.logger.error(f"æ’å…¥æ–‡ä»¶å¤±æ•—ï¼š{e}")
            return False
    
    def search_similar(self, query: str, n_results: int = 5) -> List[Dict[str, Any]]:
        """æœå°‹ç›¸ä¼¼æ–‡ä»¶
        
        Args:
            query: æŸ¥è©¢å­—ä¸²
            n_results: è¿”å›çµæœæ•¸é‡
            
        Returns:
            æœå°‹çµæœ
        """
        try:
            results = self.collection.query(
                query_texts=[query],
                n_results=n_results,
                include=["documents", "metadatas", "distances"]
            )
            
            formatted_results = []
            for i in range(len(results["documents"][0])):
                formatted_results.append({
                    "content": results["documents"][0][i],
                    "metadata": results["metadatas"][0][i],
                    "distance": results["distances"][0][i]
                })
            
            return formatted_results
            
        except Exception as e:
            self.logger.error(f"æœå°‹å¤±æ•—ï¼š{e}")
            return []
    
    def ask_gpt(self, question: str, context_docs: List[Dict[str, Any]] = None) -> str:
        """ä½¿ç”¨ GPT-4o-mini å›ç­”å•é¡Œ
        
        Args:
            question: å•é¡Œ
            context_docs: ä¸Šä¸‹æ–‡æ–‡ä»¶
            
        Returns:
            GPT å›ç­”
        """
        try:
            # å¦‚æœæ²’æœ‰æä¾›ä¸Šä¸‹æ–‡ï¼Œå…ˆæœå°‹ç›¸é—œæ–‡ä»¶
            if not context_docs:
                context_docs = self.search_similar(question, n_results=3)
            
            # å»ºç«‹ä¸Šä¸‹æ–‡å­—ä¸²
            context_text = "\n\n".join([
                f"ã€{doc['metadata'].get('title', 'Unknown')}ã€‘\n{doc['content'][:1000]}..."
                for doc in context_docs
            ])
            
            # å»ºç«‹ç³»çµ±æç¤º - å°ˆæ¥­å°éŠè§’è‰²
            system_prompt = """You are an experienced and enthusiastic tour guide specializing in Fukui Prefecture, Japan. You have extensive knowledge about local attractions, shrines, temples, culture, and travel tips.

Your responsibilities:
- Act as a professional, friendly, and knowledgeable tour guide
- Provide detailed, engaging, and well-organized information
- Include practical travel advice when relevant (opening hours, best times to visit, etc.)
- Share interesting historical and cultural context
- Use a warm, welcoming tone that makes tourists excited about visiting
- Structure your responses clearly with headings, bullet points, and organized sections when appropriate
- Provide specific recommendations and insider tips

Always respond in English with enthusiasm and expertise, as if you're personally guiding tourists through Fukui Prefecture."""
            
            # å»ºç«‹ä½¿ç”¨è€…æç¤º - æ›´å°ˆæ¥­çš„æ ¼å¼
            user_prompt = f"""Based on the following tourism information about Fukui Prefecture, please provide a comprehensive and engaging response as a professional tour guide:

ã€Tourism Informationã€‘
{context_text}

ã€Tourist Questionã€‘
{question}

Please structure your response professionally with:
1. A welcoming introduction if appropriate
2. Detailed information organized by key points
3. Practical travel tips and recommendations
4. Cultural or historical insights
5. Best times to visit or special considerations

Make it informative, engaging, and helpful for tourists planning their visit to Fukui Prefecture:"""

            # å‘¼å« GPT-4o-mini å…·æœ‰æ›´è‡ªç„¶çš„åƒæ•¸è¨­å®š
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.8,  # æé«˜å‰µæ„æ€§ï¼Œè®“å›æ‡‰æ›´è‡ªç„¶æœ‰è¶£
                max_tokens=2000,  # å¢åŠ é•·åº¦é™åˆ¶ä»¥æ”¯æ´æ›´è©³ç´°çš„å›æ‡‰
                top_p=0.9,  # æ–°å¢ top_p åƒæ•¸ä»¥æå‡å›æ‡‰å“è³ª
                frequency_penalty=0.1,  # è¼•å¾®æ¸›å°‘é‡è¤‡
                presence_penalty=0.1   # é¼“å‹µå¤šæ¨£åŒ–è¡¨é”
            )
            
            answer = response.choices[0].message.content
            self.logger.info(f"GPT å›ç­”ç”ŸæˆæˆåŠŸï¼Œå•é¡Œï¼š{question[:50]}...")
            return answer
            
        except Exception as e:
            self.logger.error(f"GPT answer generation failed: {e}")
            return f"Sorry, an error occurred while generating the answer: {str(e)}"
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """å–å¾—é›†åˆçµ±è¨ˆè³‡è¨Š
        
        Returns:
            çµ±è¨ˆè³‡è¨Š
        """
        try:
            count = self.collection.count()
            return {
                "collection_name": self.collection_name,
                "document_count": count,
                "embedding_function": "text-embedding-3-small"
            }
        except Exception as e:
            self.logger.error(f"å–å¾—çµ±è¨ˆè³‡è¨Šå¤±æ•—ï¼š{e}")
            return {}

def main():
    """ä¸»å‡½å¼ - å±•ç¤ºç³»çµ±ä½¿ç”¨ç¯„ä¾‹"""
    try:
        # åˆå§‹åŒ– ChromaDB ç®¡ç†å™¨
        print("ğŸš€ åˆå§‹åŒ– ChromaDB å‘é‡è³‡æ–™åº«...")
        chroma_manager = ChromaDBManager()
        
        # å®šç¾©æª”æ¡ˆè·¯å¾‘
        locations_file = "/Users/zhuboyuan/Desktop/University-NCHU/NCHU-Project/Project-FUKUI/src/src-LLM-Shrine/output/locations_natural_language.md"
        shrines_file = "/Users/zhuboyuan/Desktop/University-NCHU/NCHU-Project/Project-FUKUI/src/src-LLM-Shrine/output/shrines_natural_language.md"
        
        # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        if not os.path.exists(locations_file):
            print(f"âŒ æ™¯é»æª”æ¡ˆä¸å­˜åœ¨ï¼š{locations_file}")
            return
        if not os.path.exists(shrines_file):
            print(f"âŒ ç¥ç¤¾æª”æ¡ˆä¸å­˜åœ¨ï¼š{shrines_file}")
            return
        
        # è¼‰å…¥ä¸¦è™•ç†æª”æ¡ˆ
        print("ğŸ“š è¼‰å…¥ä¸¦è™•ç† Markdown æª”æ¡ˆ...")
        locations_data, shrines_data = chroma_manager.load_and_process_files(
            locations_file, shrines_file
        )
        
        # åˆä½µæ‰€æœ‰è³‡æ–™
        all_documents = locations_data + shrines_data
        print(f"ğŸ“Š ç¸½å…±è™•ç†äº† {len(all_documents)} å€‹æ–‡ä»¶")
        
        # æ’å…¥è³‡æ–™åº«
        print("ğŸ’¾ å°‡è³‡æ–™æ’å…¥ ChromaDB...")
        success = chroma_manager.insert_documents(all_documents)
        
        if success:
            print("âœ… è³‡æ–™åº«å»ºç«‹æˆåŠŸï¼")
            
            # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
            stats = chroma_manager.get_collection_stats()
            print(f"ğŸ“ˆ è³‡æ–™åº«çµ±è¨ˆï¼š{stats}")
            
            # æ¸¬è©¦å•ç­”åŠŸèƒ½
            print("\nğŸ¤– æ¸¬è©¦ GPT-4o-mini å•ç­”åŠŸèƒ½...")
            test_questions = [
                "ç¦äº•ç¸£æœ‰å“ªäº›è‘—åçš„ç¥ç¤¾ï¼Ÿ",
                "æ¨è–¦ä¸€äº›ç¦äº•ç¸£çš„æµ·å²¸æ™¯é»",
                "æ°¸å¹³å¯ºçš„ç‰¹è‰²æ˜¯ä»€éº¼ï¼Ÿ"
            ]
            
            for question in test_questions:
                print(f"\nâ“ å•é¡Œï¼š{question}")
                answer = chroma_manager.ask_gpt(question)
                print(f"ğŸ’¬ å›ç­”ï¼š{answer}\n" + "="*60)
                
        else:
            print("âŒ è³‡æ–™åº«å»ºç«‹å¤±æ•—")
            
    except Exception as e:
        print(f"âŒ åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        logging.error(f"ä¸»ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤ï¼š{e}")

if __name__ == "__main__":
    main()
