#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¦äº•è§€å…‰æ™ºèƒ½åŠ©æ‰‹ - FastAPI å¾Œç«¯æœå‹™
æä¾› ChromaDB å‘é‡è³‡æ–™åº«å’Œ OpenAI API çš„ RESTful ä»‹é¢
"""

import os
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional
import logging
import base64
import json
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Response, File, UploadFile, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel
import uvicorn
from dotenv import load_dotenv

# åŠ å…¥å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))
print(f"Project root: {project_root}")
print(f"Python path: {sys.path}")

try:
    from src.Vector_Database.ChromaDB_v1 import ChromaDBManager
    print("âœ… ChromaDB æ¨¡çµ„è¼‰å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ ChromaDB æ¨¡çµ„è¼‰å…¥å¤±æ•—: {e}")
    print("å°‡å»ºç«‹ç°¡åŒ–ç‰ˆæœ¬çš„æœå‹™")
    ChromaDBManager = None

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# å…¨åŸŸè®Šæ•¸
chroma_manager = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """æ‡‰ç”¨ç¨‹å¼ç”Ÿå‘½é€±æœŸç®¡ç†"""
    global chroma_manager
    try:
        print("ğŸš€ åˆå§‹åŒ– ChromaDB å‘é‡è³‡æ–™åº«...")
        
        if ChromaDBManager is None:
            print("âš ï¸ ChromaDB ç®¡ç†å™¨ç„¡æ³•è¼‰å…¥ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
            yield
            return
            
        chroma_manager = ChromaDBManager(
            db_path="./chroma_db",
            collection_name="fukui_tourism"
        )
        
        # æª¢æŸ¥è³‡æ–™åº«æ˜¯å¦å·²æœ‰è³‡æ–™
        stats = chroma_manager.get_collection_stats()
        if stats.get("document_count", 0) == 0:
            print("ğŸ“š è³‡æ–™åº«ç‚ºç©ºï¼Œé–‹å§‹è¼‰å…¥è³‡æ–™...")
            await load_initial_data()
        else:
            print(f"ğŸ“Š è³‡æ–™åº«å·²åŒ…å« {stats.get('document_count')} å€‹æ–‡ä»¶")
            
        print("âœ… å¾Œç«¯æœå‹™åˆå§‹åŒ–å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ å¾Œç«¯æœå‹™åˆå§‹åŒ–å¤±æ•—ï¼š{e}")
        print("å°‡ä»¥ç°¡åŒ–æ¨¡å¼é‹è¡Œ")
        chroma_manager = None
    
    yield  # æ‡‰ç”¨ç¨‹å¼åŸ·è¡Œä¸­
    
    # æ¸…ç†ç¨‹å¼ç¢¼ï¼ˆå¦‚æœéœ€è¦çš„è©±ï¼‰
    print("ğŸ”„ æ‡‰ç”¨ç¨‹å¼é—œé–‰ä¸­...")

# FastAPI æ‡‰ç”¨ç¨‹å¼
app = FastAPI(
    title="ç¦äº•è§€å…‰æ™ºèƒ½åŠ©æ‰‹ API",
    description="æä¾› ChromaDB å‘é‡è³‡æ–™åº«å’Œ OpenAI GPT-4o-mini å•ç­”åŠŸèƒ½",
    version="1.0.0",
    lifespan=lifespan
)

# è¨­å®š CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­æ‡‰è©²é™åˆ¶ç‰¹å®šåŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è¨­å®šéœæ…‹æª”æ¡ˆæœå‹™ - æä¾›æ™¯é»ç…§ç‰‡
data_path = Path(__file__).parent.parent / "data"
if data_path.exists():
    app.mount("/data", StaticFiles(directory=str(data_path)), name="data")

# Pydantic æ¨¡å‹
class ChatRequest(BaseModel):
    message: str
    include_sources: bool = True
    user_location: Optional[Dict[str, float]] = None  # {"latitude": 35.xx, "longitude": 136.xx}
    timestamp: Optional[str] = None

class ChatResponse(BaseModel):
    answer: str
    sources: List[Dict[str, Any]] = []
    success: bool = True
    error: Optional[str] = None

class LocationData(BaseModel):
    id: str
    title: str
    content: str
    metadata: Dict[str, Any]
    coordinates: Optional[Dict[str, float]] = None

class LocationsResponse(BaseModel):
    locations: List[LocationData]
    total_count: int
    success: bool = True
    error: Optional[str] = None

class SelectedLocation(BaseModel):
    id: str
    name: str
    city: str
    coordinates: Dict[str, float]

class TravelDay(BaseModel):
    id: str
    date: str
    locations: List[SelectedLocation]

class StoryRequest(BaseModel):
    travelDays: List[TravelDay]
    travel_date: Optional[str] = None

class StoryResponse(BaseModel):
    story: str
    success: bool = True
    error: Optional[str] = None

# å…¨åŸŸè®Šæ•¸
chroma_manager = None

async def load_initial_data():
    """è¼‰å…¥åˆå§‹è³‡æ–™åˆ° ChromaDB"""
    try:
        if chroma_manager is None:
            print("âš ï¸ ChromaDB ç®¡ç†å™¨ä¸å¯ç”¨ï¼Œè·³éè³‡æ–™è¼‰å…¥")
            return
            
        # å®šç¾©æª”æ¡ˆè·¯å¾‘
        base_path = Path(__file__).parent.parent
        locations_file = base_path / "output" / "locations_natural_language.md"
        shrines_file = base_path / "output" / "shrines_natural_language.md"
        
        # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        if not locations_file.exists() or not shrines_file.exists():
            print("âš ï¸ è³‡æ–™æª”æ¡ˆä¸å­˜åœ¨ï¼Œè·³éè³‡æ–™è¼‰å…¥")
            return
        
        # è¼‰å…¥ä¸¦è™•ç†æª”æ¡ˆï¼ˆä½¿ç”¨é™åˆ¶è³‡æ–™é‡ä»¥æå‡æ•ˆèƒ½ï¼‰
        locations_data, shrines_data = chroma_manager.load_and_process_files(
            str(locations_file), str(shrines_file), max_locations=50, max_shrines=50
        )
        
        # åˆä½µä¸¦æ’å…¥è³‡æ–™
        all_documents = locations_data + shrines_data
        success = chroma_manager.insert_documents(all_documents)
        
        if success:
            print(f"âœ… æˆåŠŸè¼‰å…¥ {len(all_documents)} å€‹æ–‡ä»¶")
        else:
            print("âŒ è³‡æ–™è¼‰å…¥å¤±æ•—")
            
    except Exception as e:
        print(f"âŒ è¼‰å…¥åˆå§‹è³‡æ–™å¤±æ•—ï¼š{e}")

# åœ–ç‰‡å·¥å…·å‡½å¼
def get_local_image_path(city: str, location_name: str) -> Optional[str]:
    """æ ¹æ“šåŸå¸‚å’Œæ™¯é»åç¨±æ‰¾åˆ°å°æ‡‰çš„æœ¬åœ°åœ–ç‰‡è·¯å¾‘"""
    try:
        base_path = Path(__file__).parent.parent
        image_dir = base_path / "data" / "fukui-attraction-picture" / "ç¦äº•æ™¯é»ç…§" / city
        
        if not image_dir.exists():
            print(f"Image directory not found: {image_dir}")
            return None
            
        # æ¸…ç†æ™¯é»åç¨±ï¼Œç§»é™¤å¯èƒ½å½±éŸ¿åŒ¹é…çš„å­—ç¬¦
        clean_location_name = location_name.replace('ï¼ˆ', '(').replace('ï¼‰', ')').replace(' ', '')
        
        # å˜—è©¦æ‰¾åˆ°åŒ¹é…çš„åœ–ç‰‡æª”æ¡ˆ
        image_files = list(image_dir.glob("*.png"))
        
        # ç²¾ç¢ºåŒ¹é…
        for img_file in image_files:
            clean_filename = img_file.stem.replace('ï¼ˆ', '(').replace('ï¼‰', ')').replace(' ', '')
            if clean_location_name in clean_filename or clean_filename in clean_location_name:
                print(f"Found matching image: {img_file}")
                return str(img_file)
        
        # éƒ¨åˆ†åŒ¹é…
        for img_file in image_files:
            clean_filename = img_file.stem.replace('ï¼ˆ', '(').replace('ï¼‰', ')').replace(' ', '')
            # æª¢æŸ¥é—œéµå­—åŒ¹é…
            if any(word in clean_filename for word in clean_location_name.split() if len(word) > 1):
                print(f"Found partial matching image: {img_file}")
                return str(img_file)
        
        # å¦‚æœæ²’æœ‰åŒ¹é…ï¼Œå›å‚³ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºé è¨­
        if image_files:
            print(f"Using default image: {image_files[0]}")
            return str(image_files[0])
            
    except Exception as e:
        print(f"Error getting image path: {e}")
        
    return None

@app.get("/images/{city}/{filename}")
async def get_image(city: str, filename: str):
    """æä¾›æœ¬åœ°åœ–ç‰‡æœå‹™"""
    try:
        base_path = Path(__file__).parent.parent
        image_path = base_path / "data" / "fukui-attraction-picture" / "ç¦äº•æ™¯é»ç…§" / city / filename
        
        if image_path.exists() and image_path.suffix.lower() in ['.png', '.jpg', '.jpeg']:
            return FileResponse(image_path)
        else:
            raise HTTPException(status_code=404, detail="Image not found")
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to read image: {str(e)}")

# API è·¯ç”±
@app.get("/")
async def root():
    """æ ¹è·¯å¾‘"""
    return {"message": "ç¦äº•è§€å…‰æ™ºèƒ½åŠ©æ‰‹ API æœå‹™æ­£åœ¨åŸ·è¡Œä¸­", "status": "active"}

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥"""
    if chroma_manager is None:
        raise HTTPException(status_code=503, detail="ChromaDB ç®¡ç†å™¨æœªåˆå§‹åŒ–")
    
    try:
        stats = chroma_manager.get_collection_stats()
        return {
            "status": "healthy",
            "database_stats": stats,
            "openai_configured": bool(os.getenv("OPENAI_API_KEY"))
        }
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"æœå‹™ä¸å¥åº·ï¼š{str(e)}")

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """èŠå¤©å•ç­”ç«¯é» - æ”¯æ´æ™‚é–“å’Œä½ç½®æ„ŸçŸ¥"""
    if chroma_manager is None:
        raise HTTPException(status_code=503, detail="ChromaDB ç®¡ç†å™¨æœªåˆå§‹åŒ–")
    
    try:
        # å¢å¼·æŸ¥è©¢è¨Šæ¯ï¼ŒåŠ å…¥æ™‚é–“å’Œä½ç½®è³‡è¨Š
        enhanced_message = request.message
        
        # åŠ å…¥æ™‚é–“è³‡è¨Šï¼ˆå¦‚æœæä¾›ï¼‰
        if request.timestamp:
            enhanced_message += f"\n\n[æ™‚é–“è³‡è¨Š: {request.timestamp}]"
        
        # åŠ å…¥ä½ç½®è³‡è¨Šï¼ˆå¦‚æœæä¾›ï¼‰
        location_context = ""
        if request.user_location:
            lat = request.user_location.get('latitude')
            lng = request.user_location.get('longitude')
            if lat and lng:
                location_context = f"\n\n[User location: Latitude {lat:.4f}, Longitude {lng:.4f}]"
                enhanced_message += location_context
                
                # æª¢æŸ¥ä½¿ç”¨è€…æ˜¯å¦åœ¨ç¦äº•ç¸£å¢ƒå…§æˆ–é™„è¿‘
                if is_near_fukui(lat, lng):
                    enhanced_message += "\n[Note: User is currently in or near Fukui Prefecture, please prioritize recommending nearby attractions]"
        
        # æœå°‹ç›¸é—œæ–‡ä»¶ - ä½¿ç”¨åœ°ç†ä½ç½®æ„ŸçŸ¥æœå°‹
        relevant_docs = chroma_manager.search_similar_with_location(
            enhanced_message, 
            n_results=5,
            distance_threshold_km=50.0 if request.user_location else 20.0
        )
        
        if not relevant_docs:
            return ChatResponse(
                answer="Sorry, I couldn't find relevant information. Please try asking other questions about Fukui Prefecture tourist attractions or shrines.",
                sources=[],
                success=True
            )
        
        # å»ºç«‹ç³»çµ±æç¤ºï¼ŒåŒ…å«æ™‚é–“å’Œä½ç½®æ„ŸçŸ¥
        system_prompt = f"""You are a professional Fukui Prefecture tourism guide AI assistant. Please answer questions based on the following information:

1. Time Awareness:
   - If seasonal activities are mentioned, consider the current time {request.timestamp or '(no time information provided)'}
   - Recommend the most suitable attractions and activities based on the season
   - Remind users to pay attention to operating hours and seasonal closure information

2. Location Awareness:
   {f"- User location: {location_context}" if location_context else "- No user location information provided"}
   - If the user is in Fukui Prefecture, prioritize nearby attractions
   - Provide specific transportation guidance and distance information
   - Consider actual transportation convenience

3. Response Style:
   - Respond in English
   - Provide detailed and practical information
   - Include transportation methods, opening hours, and feature introductions
   - Appropriately include local cultural background"""
        
        # ä½¿ç”¨ GPT ç”Ÿæˆå°ˆæ¥­å°éŠå¼å›ç­”
        answer = chroma_manager.ask_gpt(
            f"{system_prompt}\n\nUser question: {request.message}", 
            relevant_docs,
            use_location_aware_search=False  # å·²ç¶“ä½¿ç”¨åœ°ç†ä½ç½®æœå°‹äº†
        )
        
        # æº–å‚™ä¾†æºè³‡è¨Š
        sources = []
        if request.include_sources:
            for doc in relevant_docs:
                source_info = {
                    "title": doc['metadata'].get('title', 'Unknown'),
                    "type": doc['metadata'].get('source_type', 'unknown'),
                    "content": doc['content'][:200] + "..." if len(doc['content']) > 200 else doc['content']
                }
                
                # å¦‚æœæœ‰åœ°ç†ä½ç½®è³‡è¨Šï¼ŒåŠ å…¥è·é›¢
                if request.user_location and 'location_score' in doc:
                    source_info['location_score'] = doc['location_score']
                
                sources.append(source_info)
        
        return ChatResponse(
            answer=answer,
            sources=sources,
            success=True
        )
        
    except Exception as e:
        logging.error(f"Chat processing error: {e}")
        return ChatResponse(
            answer="Sorry, an error occurred while processing your question. Please try again later.",
            sources=[],
            success=False,
            error=str(e)
        )

def is_near_fukui(latitude: float, longitude: float, radius_km: float = 100.0) -> bool:
    """æª¢æŸ¥ä½¿ç”¨è€…æ˜¯å¦åœ¨ç¦äº•ç¸£é™„è¿‘
    
    Args:
        latitude: ä½¿ç”¨è€…ç·¯åº¦
        longitude: ä½¿ç”¨è€…ç¶“åº¦  
        radius_km: åˆ¤å®šç¯„åœï¼ˆå…¬é‡Œï¼‰
        
    Returns:
        bool: æ˜¯å¦åœ¨ç¦äº•ç¸£é™„è¿‘
    """
    # ç¦äº•ç¸£å¤§è‡´çš„ä¸­å¿ƒåº§æ¨™
    fukui_center_lat = 35.9044
    fukui_center_lng = 136.1892
    
    # è¨ˆç®—è·é›¢ï¼ˆç°¡åŒ–çš„çƒé¢è·é›¢è¨ˆç®—ï¼‰
    from math import radians, cos, sin, asin, sqrt
    
    # è½‰æ›ç‚ºå¼§åº¦
    lat1, lng1 = radians(latitude), radians(longitude)
    lat2, lng2 = radians(fukui_center_lat), radians(fukui_center_lng)
    
    # Haversine å…¬å¼
    dlat = lat2 - lat1
    dlng = lng2 - lng1
    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlng/2)**2
    distance_km = 2 * asin(sqrt(a)) * 6371  # åœ°çƒåŠå¾‘ç´„ 6371 å…¬é‡Œ
    
    return distance_km <= radius_km

@app.get("/locations", response_model=LocationsResponse)
async def get_locations(limit: int = 200, search: Optional[str] = None):
    """å–å¾—æ™¯é»ä½ç½®è³‡æ–™ç”¨æ–¼åœ°åœ–é¡¯ç¤º"""
    try:
        # è¼‰å…¥å®Œæ•´çš„æ™¯é»è³‡æ–™
        import json
        base_path = Path(__file__).parent.parent
        locations_file = base_path / "output" / "fukui_enhanced_locations.json"
        
        if not locations_file.exists():
            raise HTTPException(status_code=404, detail="æ™¯é»è³‡æ–™æª”æ¡ˆä¸å­˜åœ¨")
            
        with open(locations_file, 'r', encoding='utf-8') as f:
            locations_data = json.load(f)
        
        locations = []
        for i, location in enumerate(locations_data[:limit]):
            if search and search.lower() not in location.get('google_maps_data', {}).get('name', '').lower():
                continue
                
            google_data = location.get('google_maps_data', {})
            original_data = location.get('original_data', {})
            
            # ç²å–æœ¬åœ°åœ–ç‰‡è·¯å¾‘
            city = original_data.get('city', '')
            location_name = google_data.get('name', 'Unknown Attraction')
            local_image_path = get_local_image_path(city, location_name)
            
            # å»ºç«‹ä½ç½®ç‰©ä»¶ - å„ªå…ˆä½¿ç”¨Google Mapsçš„ç²¾ç¢ºåº§æ¨™
            coordinates = None
            
            # å„ªå…ˆä½¿ç”¨ Google Maps è³‡æ–™ä¸­çš„ç¶“ç·¯åº¦
            geometry = google_data.get('geometry', {})
            if geometry and 'location' in geometry:
                try:
                    lat_float = float(geometry['location']['lat'])
                    lng_float = float(geometry['location']['lng'])
                    # æª¢æŸ¥åº§æ¨™æ˜¯å¦åœ¨ç¦äº•ç¸£åˆç†ç¯„åœå…§
                    if 35.0 <= lat_float <= 36.5 and 135.5 <= lng_float <= 137.0:
                        coordinates = {"lat": lat_float, "lng": lng_float}
                        print(f"Using Google Maps coordinates for {location_name}: {lat_float}, {lng_float}")
                    else:
                        print(f"Google coordinates out of Fukui range for {location_name}: {lat_float}, {lng_float}")
                except (ValueError, TypeError, KeyError):
                    print(f"Invalid Google Maps coordinates for {location_name}")
            
            # å¦‚æœGoogle Mapsåº§æ¨™ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸå§‹åº§æ¨™
            if coordinates is None:
                lat = original_data.get('latitude')
                lng = original_data.get('longitude')
                
                if lat is not None and lng is not None:
                    try:
                        lat_float = float(lat)
                        lng_float = float(lng)
                        # æª¢æŸ¥åº§æ¨™æ˜¯å¦åœ¨ç¦äº•ç¸£åˆç†ç¯„åœå…§
                        if 35.0 <= lat_float <= 36.5 and 135.5 <= lng_float <= 137.0:
                            coordinates = {"lat": lat_float, "lng": lng_float}
                            print(f"Using fallback coordinates for {location_name}: {lat_float}, {lng_float}")
                        else:
                            print(f"Fallback coordinates out of Fukui range for {location_name}: {lat_float}, {lng_float}")
                    except (ValueError, TypeError):
                        print(f"Invalid fallback coordinates for {location_name}: {lat}, {lng}")
            
            locations.append(LocationData(
                id=f"location_{i}",
                title=location_name,
                content=f"Rating: {google_data.get('rating', 'N/A')}/5.0 ({google_data.get('user_ratings_total', 0)} reviews)\n"
                       f"Address: {google_data.get('formatted_address', 'Not available')}\n"
                       f"Phone: {google_data.get('phone_number', 'Not available')}\n"
                       f"Website: {google_data.get('website', 'Not available')}",
                metadata={
                    "source_type": "locations",
                    "category": "attraction",
                    "city": original_data.get('city', ''),
                    "rating": google_data.get('rating'),
                    "phone": google_data.get('phone_number'),
                    "website": google_data.get('website'),
                    "address": google_data.get('formatted_address'),
                    "photo_url": google_data.get('photos', [None])[0] if google_data.get('photos') else None,
                    "local_image": f"/images/{city}/{Path(local_image_path).name}" if local_image_path else None,
                    "unique_key": location.get('unique_key', ''),  # åŠ å…¥åŸå§‹çš„ unique_key
                    "original_location_name": original_data.get('location', location_name)  # åŠ å…¥åŸå§‹ä½ç½®åç¨±
                },
                coordinates=coordinates
            ))
        
        return LocationsResponse(
            locations=locations,
            total_count=len(locations),
            success=True
        )
        
    except Exception as e:
        logging.error(f"å–å¾—ä½ç½®è³‡æ–™éŒ¯èª¤ï¼š{e}")
        raise HTTPException(status_code=500, detail=f"å–å¾—ä½ç½®è³‡æ–™å¤±æ•—ï¼š{str(e)}")

@app.get("/shrines", response_model=LocationsResponse)
async def get_shrines(limit: int = 500, search: Optional[str] = None):
    """å–å¾—å¯ºå»Ÿç¥ç¤¾ä½ç½®è³‡æ–™ç”¨æ–¼åœ°åœ–é¡¯ç¤º"""
    try:
        # è¼‰å…¥å¯ºå»Ÿç¥ç¤¾è³‡æ–™
        import json
        base_path = Path(__file__).parent.parent
        shrines_file = base_path / "output" / "enhanced_shrines_full.json"
        
        if not shrines_file.exists():
            raise HTTPException(status_code=404, detail="å¯ºå»Ÿè³‡æ–™æª”æ¡ˆä¸å­˜åœ¨")
            
        with open(shrines_file, 'r', encoding='utf-8') as f:
            shrines_data = json.load(f)
        
        shrines = []
        for i, shrine in enumerate(shrines_data[:limit]):
            if search and search.lower() not in shrine.get('name_jp', '').lower() and search.lower() not in shrine.get('name_en', '').lower():
                continue
            
            # å–å¾—åº§æ¨™
            coordinates = None
            lat = shrine.get('lat')
            lng = shrine.get('lon')
            
            if lat is not None and lng is not None:
                try:
                    lat_float = float(lat)
                    lng_float = float(lng)
                    # æª¢æŸ¥åº§æ¨™æ˜¯å¦åœ¨ç¦äº•ç¸£åˆç†ç¯„åœå…§
                    if 35.0 <= lat_float <= 36.5 and 135.5 <= lng_float <= 137.0:
                        coordinates = {"lat": lat_float, "lng": lng_float}
                    else:
                        print(f"Shrine coordinates out of Fukui range for {shrine.get('name_jp')}: {lat_float}, {lng_float}")
                except (ValueError, TypeError):
                    print(f"Invalid shrine coordinates for {shrine.get('name_jp')}: {lat}, {lng}")
            
            # å»ºç«‹å…§å®¹æè¿°
            content_parts = []
            if shrine.get('type'):
                content_parts.append(f"é¡å‹: {shrine.get('type')}")
            if shrine.get('address'):
                content_parts.append(f"åœ°å€: {shrine.get('address')}")
            if shrine.get('phone') and shrine.get('phone') != '-':
                content_parts.append(f"é›»è©±: {shrine.get('phone')}")
            if shrine.get('founded_year') and shrine.get('founded_year') != 'ä¸æ˜':
                content_parts.append(f"å‰µå»ºå¹´ä»½: {shrine.get('founded_year')}")
            if shrine.get('enshrined_deities'):
                deities = [deity.get('name', '') for deity in shrine.get('enshrined_deities', [])]
                if deities:
                    content_parts.append(f"ç¥­ç¥: {', '.join(deities)}")
            
            content = '\n'.join(content_parts) if content_parts else shrine.get('description', '')[:200]
            
            # è™•ç†æœ€ä½³å­£ç¯€è³‡è¨Š
            best_seasons = shrine.get('best_seasons', [])
            if best_seasons:
                content += f"\næœ€ä½³åƒæ‹œå­£ç¯€: {', '.join(best_seasons)}"
                
            shrines.append(LocationData(
                id=f"shrine_{i}",
                title=shrine.get('name_jp', 'Unknown Shrine'),
                content=content,
                metadata={
                    "source_type": "shrines",
                    "category": "shrine",
                    "type": shrine.get('type', 'ç¥ç¤¾'),
                    "city": shrine.get('city', ''),
                    "prefecture": shrine.get('prefecture', 'ç¦äº•çœŒ'),
                    "name_en": shrine.get('name_en', ''),
                    "romaji": shrine.get('romaji', ''),
                    "address": shrine.get('address', ''),
                    "phone": shrine.get('phone', ''),
                    "url": shrine.get('url', ''),
                    "founded_year": shrine.get('founded_year', ''),
                    "goshuin": shrine.get('goshuin', False),
                    "admission_fee": shrine.get('admission_fee', 0),
                    "wheelchair_access": shrine.get('wheelchair_access', False),
                    "best_seasons": shrine.get('best_seasons', []),
                    "enshrined_deities": shrine.get('enshrined_deities', []),
                    "gate_open": shrine.get('gate_open', ''),
                    "gate_close": shrine.get('gate_close', '')
                },
                coordinates=coordinates
            ))
        
        return LocationsResponse(
            locations=shrines,
            total_count=len(shrines),
            success=True
        )
        
    except Exception as e:
        logging.error(f"å–å¾—å¯ºå»Ÿè³‡æ–™éŒ¯èª¤ï¼š{e}")
        raise HTTPException(status_code=500, detail=f"å–å¾—å¯ºå»Ÿè³‡æ–™å¤±æ•—ï¼š{str(e)}")

@app.get("/search")
async def search_locations(query: str, limit: int = 10):
    """æœå°‹ç‰¹å®šæ™¯é»æˆ–ç¥ç¤¾"""
    if chroma_manager is None:
        raise HTTPException(status_code=503, detail="ChromaDB ç®¡ç†å™¨æœªåˆå§‹åŒ–")
    
    try:
        results = chroma_manager.search_similar(query, n_results=limit)
        
        formatted_results = []
        for result in results:
            formatted_results.append({
                "title": result['metadata'].get('title', 'Unknown'),
                "type": result['metadata'].get('source_type', 'unknown'),
                "content": result['content'][:300] + "..." if len(result['content']) > 300 else result['content'],
                "metadata": result['metadata']
            })
        
        return {
            "query": query,
            "results": formatted_results,
            "total_found": len(formatted_results)
        }
        
    except Exception as e:
        logging.error(f"æœå°‹éŒ¯èª¤ï¼š{e}")
        raise HTTPException(status_code=500, detail=f"æœå°‹å¤±æ•—ï¼š{str(e)}")

@app.post("/api/generate-story", response_model=StoryResponse)
async def generate_story(
    locations: str = Form(...),
    travel_date_range: str = Form(...),
    images: List[UploadFile] = File(default=[])
):
    """Generate Fukui travel story book"""
    try:
        # Parse locations data
        locations_data = json.loads(locations)
        travel_date_range_data = json.loads(travel_date_range)
        
        if not locations_data:
            raise HTTPException(status_code=400, detail="At least one location is required")
        
        # Process uploaded images
        image_descriptions = []
        for i, image in enumerate(images):
            if image.content_type and image.content_type.startswith('image/'):
                # Read image content
                image_content = await image.read()
                # Convert image to base64
                image_base64 = base64.b64encode(image_content).decode('utf-8')
                image_descriptions.append(f"Image {i+1}: {image.filename}")
        
        # Prepare OpenAI API request
        import openai
        from openai import OpenAI
        
        # Set up OpenAI client
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            raise HTTPException(
                status_code=500, 
                detail="OpenAI API key not configured. Please set OPENAI_API_KEY environment variable."
            )
        client = OpenAI(api_key=openai_api_key)
        
        # Build travel itinerary string with dates
        itinerary_info = []
        locations_by_date = {}
        
        # Group locations by date
        for location in locations_data:
            date = location.get('date', 'Unknown Date')
            if date not in locations_by_date:
                locations_by_date[date] = []
            locations_by_date[date].append(location)
        
        # Create itinerary info
        for date, day_locations in locations_by_date.items():
            day_info = []
            for loc in day_locations:
                coords = loc.get('coordinates', {})
                lat = coords.get('latitude', 0)
                lng = coords.get('longitude', 0)
                day_info.append(f"  - {loc['name']} ({loc['city']}) - Located at latitude {lat:.6f}, longitude {lng:.6f}")
                if loc.get('description'):
                    day_info.append(f"    Personal experience: {loc['description']}")
            
            formatted_date = date
            try:
                # Try to format the date nicely
                from datetime import datetime
                date_obj = datetime.strptime(date, '%Y-%m-%d')
                formatted_date = date_obj.strftime('%B %d, %Y')
            except:
                pass
            
            itinerary_info.append(f"Date: {formatted_date}\n" + "\n".join(day_info))
        
        locations_info = "\n\n".join(itinerary_info) if itinerary_info else "No specific itinerary provided"
        
        # Build image information string
        images_info = "\n".join(image_descriptions) if image_descriptions else "No photos uploaded"
        
        # Get travel date range info
        start_date = travel_date_range_data.get('start', 'Unknown')
        end_date = travel_date_range_data.get('end', 'Unknown')
        travel_period = f"{start_date} to {end_date}"
        
        # Prepare system prompt
        system_prompt = """You are a professional travel writer specializing in creating engaging and informative travel stories.
Please create a beautiful travel story based on the provided Fukui prefecture location information and travel dates.

The story should include:
1. An engaging introduction mentioning the travel period
2. Detailed descriptions and experiences for each location, organized by date
3. Emotional journey progression
4. Deep appreciation for Fukui's culture and beauty
5. A warm and memorable conclusion

Writing style requirements:
- Use English language
- Beautiful, emotional language
- Clear structure and logical flow
- Suitable for sharing on social media or blogs
- Approximately 800-1200 words
- Include specific dates and locations in the narrative
- Make the story feel personal and authentic
- Organize the story by travel dates"""

        # Prepare user prompt
        user_prompt = f"""Please create a Fukui travel story for me based on the following travel information:

Travel Period: {travel_period}

Travel Itinerary:
{locations_info}

Photo Information:
{images_info}

Please create a vivid and engaging travel story that makes readers feel like they experienced this Fukui journey themselves. Include the specific dates and locations in a natural way throughout the narrative. Organize the story by travel dates to show the progression of the journey."""

        # Call OpenAI API
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=2000,
            temperature=0.8
        )
        
        # Extract generated story
        story = response.choices[0].message.content
        
        return StoryResponse(
            story=story,
            success=True
        )
        
    except json.JSONDecodeError:
        raise HTTPException(status_code=400, detail="Invalid travel days data format")
    except openai.AuthenticationError:
        raise HTTPException(status_code=500, detail="OpenAI API authentication failed, please check API key")
    except openai.RateLimitError:
        raise HTTPException(status_code=429, detail="API rate limit exceeded, please try again later")
    except openai.APIError as e:
        raise HTTPException(status_code=500, detail=f"OpenAI API error: {str(e)}")
    except Exception as e:
        logging.error(f"Story generation error: {e}")
        raise HTTPException(status_code=500, detail=f"Story generation failed: {str(e)}")

if __name__ == "__main__":
    # é–‹ç™¼æ¨¡å¼åŸ·è¡Œ - å„ªåŒ–è¨­å®šä»¥æé«˜ç©©å®šæ€§
    import signal
    import sys
    
    def signal_handler(sig, frame):
        print('\nğŸ”„ æ­£åœ¨é—œé–‰æœå‹™...')
        sys.exit(0)
    
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    print("ğŸš€ æ­£åœ¨å•Ÿå‹•ç¦äº•è§€å…‰æ™ºèƒ½åŠ©æ‰‹å¾Œç«¯æœå‹™...")
    print(f"ğŸ“¡ æœå‹™å°‡åœ¨ http://0.0.0.0:8001 å•Ÿå‹•")
    print(f"ğŸ“Š å¥åº·æª¢æŸ¥ç«¯é»: http://localhost:8001/health")
    print("æŒ‰ Ctrl+C åœæ­¢æœå‹™")
    
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8001,
        reload=False,  # ç¦ç”¨è‡ªå‹•é‡æ–°è¼‰å…¥ä»¥æé«˜ç©©å®šæ€§
        log_level="info",
        access_log=True,
        server_header=False,
        date_header=False
    )
